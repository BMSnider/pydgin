#!/usr/bin/env python
#=========================================================================
# tpa-uarch-gmean-scatter-plot [options]
#=========================================================================
#
#  -h --help           Display this message
#
#   --g_ncores         Number of cores
#   --g_insn_ports     Number of instruction ports
#   --g_resources      Number of backend resources
#   --runtime          Select runtime
#                       [spmd,wsrt]
#
# Author : Shreesha Srinath
# Date   : February 25th, 2018
#
# Script calculates the geo-mean for normalized delay and work across all
# apps for each static uarch and the knob configuration and outputs the
# list of pareto-optimal points
#

import argparse
import re
import math
import sys

import pandas as pd
pd.set_option('display.width', 1000)

from scipy.stats.mstats import gmean

import brg_plot

from collections import OrderedDict

from common import *
from common_configs import *

#-------------------------------------------------------------------------
# Command line processing
#-------------------------------------------------------------------------

class ArgumentParserWithCustomError(argparse.ArgumentParser):
  def error( self, msg = "" ):
    if ( msg ): print("\n ERROR: %s" % msg)
    print("")
    file = open( sys.argv[0] )
    for ( lineno, line ) in enumerate( file ):
      if ( line[0] != '#' ): sys.exit(msg != "")
      if ( (lineno == 2) or (lineno >= 4) ): print( line[1:].rstrip("\n") )

def parse_cmdline():
  p = ArgumentParserWithCustomError( add_help=False )

  # Standard command line arguments

  p.add_argument( "-h", "--help",    action="store_true" )

  # Additional commane line arguments for the simulator

  p.add_argument( "--g_ncores",     type=int, action="store", default=4)
  p.add_argument( "--g_insn_ports", type=int, action="store", default=4)
  p.add_argument( "--g_resources",  type=int, action="store", default=4)

  p.add_argument( "--runtime", action="store", default="spmd",
                  choices=["spmd", "wsrt"])

  opts = p.parse_args()
  if opts.help: p.error()
  return opts

#-------------------------------------------------------------------------
# normalize results
#-------------------------------------------------------------------------
# computes normalized delay and normalized work for each config

def normalize_results( df, runtime ):
  base_cfg = g_mimd_base_str % runtime
  df['normalized_delay'] = df['steps']
  df['normalized_work']  = df['unique_work']
  for app in app_list:
    try:
      base_steps = float(df.loc[(df.app == app) & (df.config == base_cfg), 'steps'].iloc[0])
      df.loc[(df.app==app) & df.config.str.contains(runtime), 'normalized_delay'] = \
        df.loc[(df.app==app) & df.config.str.contains(runtime), 'normalized_delay'] / base_steps
      base_work = float(df.loc[(df.app == app) & (df.config == base_cfg), 'total_work'].iloc[0])
      df.loc[(df.app==app) & df.config.str.contains(runtime), 'normalized_work'] = \
        df.loc[(df.app==app) & df.config.str.contains(runtime), 'normalized_work'] * 100/ base_work
    except:
      continue
  return df    

#-------------------------------------------------------------------------
# is_pareto_front()
#-------------------------------------------------------------------------
# reference:
# http://hinnefe2.github.io/python/tools/2015/09/21/mario-kart.html

def is_pareto_front(row, stats, xlabel, ylabel):
  x = row[xlabel]
  y = row[ylabel]

  # look for points with the same y value but smaller x value
  is_min_x = stats.loc[stats[ylabel]==y].max()[xlabel] >= x
  # look for points with the same x value but smaller y value
  is_min_y = stats.loc[stats[xlabel]==x].max()[ylabel] >= y

  # look for points that are smaller in both x and y
  is_min_xy = len(stats.loc[(stats[xlabel]<x) & (stats[ylabel]<y)])==0

  return is_min_x and is_min_y and is_min_xy

#-------------------------------------------------------------------------
# get_pareto_data()
#-------------------------------------------------------------------------

def get_pareto_data( frame_data ):  
  columns=['config','delay','work']
  stats = pd.DataFrame(frame_data,columns=columns)  
  is_pareto = stats.apply(lambda row: is_pareto_front(row, stats, 'delay', 'work'), axis=1)
  configs = stats.loc[is_pareto,'config'].tolist()
  configs_dict = format_config_names() 
  pareto_configs = [configs_dict[x] for x in configs]
  for cfg in pareto_configs:
    print cfg
  pareto_data = stats.loc[is_pareto].sort_values(by='delay')
  return [pareto_data['delay'].values, pareto_data['work'].values]

#-------------------------------------------------------------------------
# plot
#-------------------------------------------------------------------------

def plot( raw_df, runtime ):

  # get all configs seperated into lists that are indexed based on the
  # static configuration
  group_dict = populate_configs()
  norm_df = normalize_results( raw_df, runtime )
  # only collect the dataframe of interest
  df = norm_df.loc[norm_df.config.str.contains(runtime)]

  #-----------------------------------------------------------------------
  # scatter plot
  #-----------------------------------------------------------------------

  # create plot options dict
  opts = brg_plot.PlotOptions()
  attribute_dict = \
  {
    'show'            : False,
    'plot_type'       : 'scatter',
    'figsize'         : (8.0, 8.0),
    'rotate_labels'   : False,
    'markersize'      : 60,
    'labels_fontsize' : 1,
    'legend_enabled'  : False,
  }
  for name, value in attribute_dict.iteritems():
    setattr( opts, name, value )

  # plot array 
  opts.num_cols = 1
  opts.num_rows = 1
  
  index = 0
  data = []
  # add baseline mimd [delay,work]
  data.append( [[1,100]] )
  frame_data = []
  for group, config_list in group_dict.iteritems():
    temp = []
    for cfg in config_list:
      try: 
        delay = gmean(df.loc[df.config == cfg, 'normalized_delay'])
        work  = gmean(df.loc[df.config == cfg, 'normalized_work'])
        temp.append( [delay, work] )
        frame_data.append([cfg,delay,work])
      except:
        print "Exception: {%s,%s,%s}" % ( group, app, cfg )
        continue
    data.append( temp )

  pareto_data = get_pareto_data( frame_data )

  # add plot
  opts.yrange         = [0,105]
  opts.data           = data  
  opts.pareto_points  = True
  opts.pareto_data    = pareto_data
  opts.labels         = [[],g_cfg_labels]
  opts.legend_ncol    = len(g_cfg_labels)/2
  opts.legend_enabled = True
  opts.plot_idx       = index+1
  opts.colors         = brg_plot.colors['unique20']
  opts.title          = runtime
  opts.ylabel         = 'Normalized Work % (geo. mean)'
  opts.xlabel         = 'Normalized Delay (geo. mean)'

  if index == opts.num_rows*opts.num_cols-1:
    opts.file_name = 'scatter-all.pdf'

  index = index + 1

  # plot data
  brg_plot.add_plot( opts )

#-------------------------------------------------------------------------
# main
#-------------------------------------------------------------------------

if __name__ == "__main__":
  opts = parse_cmdline()

  g_insn_ports = opts.g_insn_ports
  g_ncores     = opts.g_ncores
  g_resources  = opts.g_resources

  # read the results
  df = pd.read_csv( g_sim_results_file )

  # only select non-zero values as zero is missing data at the moment
  df = df[df!=0]

  # create plots
  plot( df, opts.runtime )
